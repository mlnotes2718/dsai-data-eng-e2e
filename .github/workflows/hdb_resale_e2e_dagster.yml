name: HDB Resale E2E Dagster 

on:
  # push: # use in production stage
  #  branches:
  #    - main  # Adjust if you want to trigger on different branches
  workflow_dispatch:  # Enables manual triggering from GitHub UI
  # schedule:
  #  - cron: '0 15 * * 2'  # Runs every Tuesday at 3pm UTC (11pm SG time)

jobs:
  run-script:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./hdb_resale_e2e_dagster

    # Set environment variables for the entire job
    env:
      TAP_POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
      TAP_POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
      BIGQUERY_SERVICE_ACCOUNT_KEY: ${{ secrets.BIGQUERY_SERVICE_ACCOUNT_KEY }} 
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Setup Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: dagster
          environment-file: ./hdb_resale_e2e_dagster/dagster-environment.yml

      - name: Write BigQuery Service Account Key to File
        run: echo "$BIGQUERY_SERVICE_ACCOUNT_KEY" > /tmp/bq-key.json

      - name: Set GOOGLE_APPLICATION_CREDENTIALS env
        run: echo "GOOGLE_APPLICATION_CREDENTIALS=/tmp/bq-key.json" >> $GITHUB_ENV

      # Add this to ensure Meltano plugins (tap/target) are available
      - name: Meltano Install
        shell: bash -l {0}
        run: |
          cd meltano_hdb_resale
          meltano install

      - name: dbt Dependencies
        env: 
          TARGET: dev
        shell: bash -l {0}
        run: |
          cd dbt_hdb_resale
          dbt deps 
          dbt compile --target $TARGET

      - name: Run Dagster Asset
        shell: bash -l {0}
        env:
          TARGET: dev
          # If your definitions.py is not in the root of the working-directory, 
          # specify it here using -m or -f
        run: |
          cd dagster_dbt_integration_hdb_resale
          dagster asset materialize --select "*" -m dagster_dbt_integration_hdb_resale.definitions | tee pipeline_log.txt
      


## The following is the setup for Email notification

## Additional secrets is required
## COLLABORATORS_EMAILS : contain list of email
## MAIL_USERNAME : email account to send notification (Tested good with GMAIL)
## MAIL_PASSWORD : email password (Not the password to the Gmail but App Password Generate from Gmail) 
##     COPY and PASTE ONLY FROM APP PASSWORD GENERATOR TO GITHUB SECRETS (Other form of copy and paste do not work)


      - name: Prepare Email Body
        if: always()
        run: |
          echo "### Dagster Pipeline Execution Report" > email_body.txt
          echo "Environment: ${{ env.TARGET }}" >> email_body.txt
          echo "Status: ${{ job.status }}" >> email_body.txt
          echo "-----------------------------------" >> email_body.txt
          echo "Last 100 lines of logs:" >> email_body.txt
          echo '```' >> email_body.txt
          if [ -f pipeline_log.txt ]; then
            tail -n 100 pipeline_log.txt >> email_body.txt
          else
            echo "No log file found." >> email_body.txt
          fi
          echo '```' >> email_body.txt

      - name: Upload Full Pipeline Log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: full-dagster-log-${{ github.run_id }}
          path: pipeline_log.txt
          retention-days: 7  # Keeps the repo clean after a week

      - name: Send Mail
        if: always()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          secure: false 
          username: ${{ secrets.MAIL_USERNAME }}
          password: ${{ secrets.MAIL_PASSWORD }}
          subject: Dagster Pipeline Status - ${{ job.status }}
          to: your-email@example.com
          from: GitHub Actions Orchestrator
          body: file://email_body.txt